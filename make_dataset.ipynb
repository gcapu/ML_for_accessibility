{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag, Comment\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal is to list all the tags\n",
    "\n",
    "def recursive_decomp(tag, i=0):\n",
    "    tags = []\n",
    "    if isinstance(tag, Comment):\n",
    "        pass\n",
    "    elif isinstance(tag, NavigableString):\n",
    "        if tag.string != '\\n':\n",
    "            tags.append(str(tag.string))\n",
    "    elif isinstance(tag, Tag):\n",
    "        if tag.has_attr('aria-label'):\n",
    "            tags.append(tag['aria-label'])\n",
    "        elif tag.has_attr('aria-labelledby'):\n",
    "            label_tag = tag.find(id=tag['aria-labelledby'])\n",
    "            if label_tag is not None:\n",
    "                tags.append(str(label_tag.string))\n",
    "        elif tag.name == u'img' and tag.has_attr('alt'):\n",
    "            tags.append(tag['alt'])\n",
    "        elif tag.name in [u'script', u'style']:\n",
    "            pass\n",
    "        else:\n",
    "            for child in tag.children:\n",
    "                tags += recursive_decomp(child)\n",
    "    else:\n",
    "        for child in tag:\n",
    "            tags += recursive_decomp(child, i+1)   \n",
    "    return tags\n",
    "\n",
    "def get_element_location(element):\n",
    "    result = None\n",
    "    while (element.parent):\n",
    "        if element.parent.name in ['header','body','footer']:\n",
    "            result = element.parent.name\n",
    "            break\n",
    "        else:\n",
    "            element = element.parent\n",
    "    return result\n",
    "\n",
    "def navs_with_labels(soup):\n",
    "    navs = []\n",
    "    for result in soup.findAll(\"div\", {\"role\" : \"navigation\"}):\n",
    "        if get_aria_label(result, soup) is not None:\n",
    "            navs.append(result)\n",
    "    for result in soup.findAll(\"nav\"):\n",
    "        if get_aria_label(result, soup) is not None:\n",
    "            navs.append(result)\n",
    "    return navs\n",
    "\n",
    "def get_aria_label(tag, soup = None):\n",
    "    \"\"\" gets the aria label from the tag. \n",
    "    \n",
    "    It requires the soup in case it has aria-labelledby\"\"\"\n",
    "    if tag.has_attr('aria-label'):\n",
    "        return tag['aria-label']\n",
    "    elif tag.has_attr('aria-labelledby') and soup is not None:\n",
    "        label = soup.find(id=tag['aria-labelledby'])\n",
    "        if label is not None:\n",
    "            return label.string\n",
    "        else: \n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1508/1508 [02:14<00:00, 11.22it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "# end = False\n",
    "dir = './sites'\n",
    "with open('useful.txt', 'r') as ufile:\n",
    "    data = json.load(ufile)\n",
    "    for file in tqdm(data):\n",
    "        with open(f'{dir}/{file}', 'r') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "            navs = navs_with_labels(soup)\n",
    "            for i, nav in enumerate(navs):\n",
    "                entry = {}\n",
    "                entry['label'] = get_aria_label(nav, soup)\n",
    "                entry['index'] = i\n",
    "                entry['location'] = get_element_location(nav)\n",
    "                entry['words'] = recursive_decomp(nav.children)\n",
    "#                 for sentence in entry['words']:\n",
    "#                     if 'span' in normalizeString(sentence).split():\n",
    "#                         print(file)\n",
    "#                         print((sentence))\n",
    "#                         print(\"---------\")\n",
    "#                         print(nav)\n",
    "#                         end = True\n",
    "#                         break\n",
    "#                 if end:\n",
    "#                     break\n",
    "                dataset.append(entry)\n",
    "#         if end:\n",
    "#             break\n",
    "        \n",
    "with open('dataset.json', 'w') as ofile:\n",
    "    json.dump(dataset, ofile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
